{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "НН(8).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrmIOe9e5nT84rMn9qxJ6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Barashek-1507/SRDandA/blob/master/%D0%9D%D0%9D(8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYKoVTkwPC7D",
        "outputId": "6f8a8767-fed8-4360-e9c5-c830739b3272"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Сперва создадим тензор x:\n",
        "x = torch.tensor([[10., 20.]])\n",
        "\n",
        "# Оригинальный полносвязный слой с 2-мя входами и 3-мя нейронами (выходами):\n",
        "fc = torch.nn.Linear(2, 3)\n",
        "\n",
        "# Веса fc-слоя хранятся в fc.weight, а bias'ы соответственно в fc.bias\n",
        "# fc.weight и fc.bias по умолчанию инициализируются случайными числами\n",
        "\n",
        "# Давайте проставим свои значения в веса и bias'ы:\n",
        "w = torch.tensor([[11., 12.], [21., 22.], [31., 32]])\n",
        "fc.weight.data = w\n",
        "\n",
        "b = torch.tensor([[31., 32., 33.]])\n",
        "fc.bias.data = b\n",
        "\n",
        "# Получим выход fc-слоя:\n",
        "fc_out = fc(x)\n",
        "\n",
        "# Попробуем теперь получить аналогичные выходы с помощью матричного перемножения:\n",
        "fc_out_alternative =   torch.mm(x, torch.t(w))+b\n",
        "\n",
        "# Проверка осуществляется автоматически вызовом функции\n",
        "print(fc_out == fc_out_alternative)\n",
        "# (раскомментируйте, если решаете задачу локально)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[True, True, True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQIOZed5RPMB",
        "outputId": "211b9162-2ce0-4d32-b892-b4294ff8e79b"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Сперва создадим тензор x:\n",
        "x = torch.tensor([[10., 20.]])\n",
        "\n",
        "# Оригинальный полносвязный слой с 2-мя входами и 3-мя нейронами (выходами):\n",
        "fc = torch.nn.Linear(2, 3)\n",
        "\n",
        "# Веса fc-слоя хранятся в fc.weight, а bias'ы соответственно в fc.bias\n",
        "# fc.weight и fc.bias по умолчанию инициализируются случайными числами\n",
        "\n",
        "# Давайте проставим свои значения в веса и bias'ы:\n",
        "w = torch.tensor([[11., 12.], [21., 22.], [31., 32]])\n",
        "fc.weight.data = w\n",
        "\n",
        "b = torch.tensor([[31., 32., 33.]])\n",
        "fc.bias.data = b\n",
        "\n",
        "# Получим выход fc-слоя:\n",
        "fc_out = fc(x)\n",
        "# Просуммируем выход fc-слоя, чтобы получить скаляр:\n",
        "fc_out_summed = fc_out.sum()\n",
        "\n",
        "# Посчитаем градиенты формулы fc_out_summed:\n",
        "fc_out_summed.backward()\n",
        "weight_grad = fc.weight.grad\n",
        "bias_grad = fc.bias.grad\n",
        "\n",
        "# Ok, теперь воспроизведем вычисления выше но без fc-слоя:\n",
        "# Проставим, что у \"w\" и \"b\" нужно вычислять градиенты (для fc-слоя это произошло автоматически):\n",
        "w.requires_grad_(True)\n",
        "b.requires_grad_(True)\n",
        "\n",
        "# Получим выход нашей формулы:\n",
        "our_formula = (torch.mm(x, torch.t(w))+b).sum()\n",
        "\n",
        "# Сделайте backward для нашей формулы:\n",
        "our_formula.backward()\n",
        "\n",
        "# Проверка осуществляется автоматически, вызовом функций:\n",
        "print('fc_weight_grad:', weight_grad)\n",
        "print('our_weight_grad:', w.grad)\n",
        "print('fc_bias_grad:', bias_grad)\n",
        "print('out_bias_grad:', b.grad)\n",
        "# (раскомментируйте, если работаете над задачей локально)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc_weight_grad: tensor([[10., 20.],\n",
            "        [10., 20.],\n",
            "        [10., 20.]])\n",
            "our_weight_grad: tensor([[10., 20.],\n",
            "        [10., 20.],\n",
            "        [10., 20.]])\n",
            "fc_bias_grad: tensor([[1., 1., 1.]])\n",
            "out_bias_grad: tensor([[1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}